# ğŸ£ MLFS â€“ Machineâ€¯Learningâ€¯FileÂ­system ğŸ£

*Mount your model like a USB stick and `cd` straight into its brain.*

---

## ğŸ¤”  Whatâ€theâ€heckâ€‘isâ€‘this?

MLFS is a tiny <abbr title="Filesystem in Userspace">FUSE</abbr> driver that turns a **PyTorch** model into a directory tree:

```
/sys/          â† version, banner, full model string
/model/        â† every layer â†’ folder  â€¢   tensors â†’ files  â€¢   grads â†’ *.grad
/activations/  â† forwardâ€‘pass dumps
/ir/           â† TorchScript graph
/logs/         â† tail â€‘f me plz
```

`ls`, `cat`, `diff`, `grep`â€¦ if your shell can touch it, it can now poke your networkâ€™s guts.

---

## âš¡ï¸ 10â€‘second install

```bash
sudo apt install fuse              # (Linux) â€“ macOS: brew install macfuse
pip install torch torchvision fusepy
```

---

## ğŸ¸  Mount nâ€™ Roll

```bash
# make a playground mountpoint
sudo mkdir -p /mnt/mlfs

# export any .pt you like (here we cook a ResNetâ€‘18)
python - <<'PY'
import torch, torchvision as tv
torch.save(tv.models.resnet18(weights=None), 'resnet18.pt')
PY

# fire it up (foreground, ctrlâ€‘c to quit)
sudo ./mlfs.py --model resnet18.pt --mount /mnt/mlfs --foreground
```

Now try the shellâ€‘fu:

```bash
ls /mnt/mlfs/model/conv1
hexdump -C /mnt/mlfs/model/conv1/weight.bin | head -n 4

echo "hello logğŸ‘‹" | sudo tee -a /mnt/mlfs/logs/fuse.log
```

Unmount when done:

```bash
sudo fusermount -u /mnt/mlfs   # linux
# sudo umount /mnt/mlfs        # macOS
```

---

## ğŸ£  Example 1 â€” Tiny MLP *quick\_demo.py*

```bash
cd mlfs/examples
sudo python3 quick_demo.py
```

Watch it:

1. Builds a 2â€‘layer MLP on the fly.
2. Mounts MLFS in a temp dir.
3. Hexâ€‘spills the first 16 bytes of the weight matrix.
4. Patches one gradient byte (because we can âœ¨).
5. Cleans all traces like a ninja.

---

## ğŸ¦–  Example 2 â€” ResNetâ€‘18 *resnet\_demo.py*

```bash
sudo python3 examples/resnet_demo.py
```

This heftier demo lists deep subâ€‘blocks (`layer1/0/conv1`) and dumps the raw conv1 tensor to prove MLFS handles real architectures.

---

## ğŸ› ï¸ 12 actuallyâ€‘useful things you can do (a totally serious list)

| #  | Useâ€‘case                                                                   | Emoji vibe |
| -- | -------------------------------------------------------------------------- | ---------- |
| 1  | **Unixâ€‘native surgery** â€“ `vim` a bias, save, watch trainer hotâ€‘reload     | ğŸ©º         |
| 2  | **Activation scooping** â€“ `inotifywait` + CSV dumps, zero extra hooks      | ğŸ¦         |
| 3  | **Timeâ€‘travel debugging** â€“ `git checkout stepâ€‘1337` and remount           | âŒ›ï¸         |
| 4  | **Quick viz** â€“ point TensorBoard at weight files (no writer boilerâ€‘plate) | ğŸ–¼ï¸        |
| 5  | **Remote prod inspection** â€“ `sshfs` into a containerized model            | ğŸ›°ï¸        |
| 6  | **CI sanity** â€“ fail build if any `*.grad` == 0 bytes ğŸ¤¨                   | ğŸ”¨         |
| 7  | **Observability** â€“ Grafana agent tails `/logs/fuse.log`                   | ğŸ“‰         |
| 8  | **Fuseâ€‘RPC inference** â€“ write input tensor, read output, no gRPC          | ğŸ“¡         |
| 9  | **Edutainment** â€“ students literally `cd` into ResNet tunnels              | ğŸ“         |
| 10 | **Security diff** â€“ hash all blobs, alarm on tamper                        | ğŸ›¡ï¸        |
| 11 | **Delta checkpoints** â€“ `rsync --inplace` on file blobs                    | ğŸ’¾         |
| 12 | **Lazy mmap serving** â€“ roadmap: weights stay on disk, pageâ€‘in live        | ğŸ›¸         |

---

## ğŸ—ºï¸  Roadmap (a.k.a. TODO or bust)

* ğŸ› Refactor singleâ€‘file prototype â†’ proper package.
* ğŸ“¦ `pip install mlfs` dream.
* ğŸ“Š Autoâ€‘populate `/activations/<timestamp>/` on forward hooks.
* âœï¸ Writable weight surgery (`echo 0.0 > â€¦/weight.bin`).
* ğŸŒŒ mmapâ€‘backed giantâ€‘model support.

---

## ğŸ§â€â™‚ï¸  License

MIT.  Go forth and mount exotically.

> â€œ**Everything is a file**â€¦ even a 175â€‘billionâ€‘parameter fever dream.â€ â€“ some POSIX wizard
